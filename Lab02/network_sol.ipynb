{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (solution) Road networks structure analysis: A preliminary network science-based approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import powerlaw\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "\n",
    "from keplergl import KeplerGl\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_CRS = 'EPSG:32633'\n",
    "WORLD_CRS = 'EPSG:4326'\n",
    "\n",
    "CITY_NAME = \"Graz, Austria\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the road network of Graz\n",
    "G = ox.graph_from_place(CITY_NAME, network_type='drive', simplify= True) # a network is often represented by the letter G \n",
    "G = ox.project_graph(G, to_crs=MAIN_CRS) # this give a multigraph\n",
    "\n",
    "G_simple = nx.DiGraph(G) # this give a simple directed graph\n",
    "\n",
    "# print basic stats of the network\n",
    "stats_json = ox.stats.basic_stats(G)\n",
    "print(json.dumps(stats_json, indent=2)) # make the print output prettier \n",
    "\n",
    "# plot the network\n",
    "fig, ax = ox.plot_graph(G, node_size=5, bgcolor= \"#040615\", node_color='#f1f1f1', edge_color='#d44e5c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_centrality = pd.DataFrame.from_dict(centrality, orient='index', columns=['value'])\n",
    "print(\"average centrality: \",(df_centrality['value'] * df_centrality.index).sum() / df_centrality['value'].sum())\n",
    "\n",
    "fig = px.bar(df_centrality)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centralities Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. extract nodes and edges\n",
    "df_nodes, df_edges = ox.graph_to_gdfs(G, nodes=True)\n",
    "\n",
    "# 2. Compute all metrics once and store them in a dictionary\n",
    "metrics = {\n",
    "    # \"column_name\": \"values dict\"\n",
    "    \"centrality\":  nx.degree_centrality(G),\n",
    "    \"knn\":         nx.average_neighbor_degree(G),\n",
    "    \"closeness\":   nx.closeness_centrality(G),\n",
    "    \"betweenness\": nx.betweenness_centrality(G, weight=\"length\"), # long process\n",
    "    \"eigenvector\": nx.eigenvector_centrality(G_simple, max_iter=1000),\n",
    "    \"pagerank\":    nx.pagerank(G, alpha=0.9),\n",
    "}\n",
    "\n",
    "# 3. Add each metric as a new column in df_nodes\n",
    "for column_name, values_dict in metrics.items():\n",
    "    for metric, value in metrics.items():\n",
    "        # values_dict is: {node: value} -> create a series from the dictionary with the nodes as the index.\n",
    "        df_nodes[column_name] = pd.Series(values_dict)\n",
    "\n",
    "map = KeplerGl(height=600)\n",
    "map.add_data(data=df_nodes, name=\"nodes_Graz\")\n",
    "map.add_data(data=df_edges, name=\"edges_Graz\")\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nodes.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(df_nodes[['centrality', 'closeness', 'betweenness', 'eigenvector']].sample(1000).reset_index(drop=True))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the data using powerlaw, starting from minimum degree 1\n",
    "fit = powerlaw.Fit(df_nodes['street_count'], xmin=1)\n",
    "\n",
    "# Plot the  with fits (this matches the style of the provided graph)\n",
    "fig = fit.plot_ccdf(color='black', label='Empirical Data')\n",
    "fit.power_law.plot_ccdf(color='r', linestyle='--', ax=fig, label='Power Law')\n",
    "fit.lognormal.plot_ccdf(color='g', linestyle='--', ax=fig, label='Lognormal')\n",
    "fit.stretched_exponential.plot_ccdf(color='b', linestyle='--', ax=fig, label='Stretched exponential')\n",
    "\n",
    "# Customize the plot to match the example\n",
    "\n",
    "fig.legend(loc='lower left')\n",
    "plt.show()\n",
    "\n",
    "# To compare fits, use likelihood ratio tests\n",
    "print(\"Power law vs Lognormal:\", fit.distribution_compare('power_law', 'lognormal'))\n",
    "print(\"Power law vs Exponential:\", fit.distribution_compare('power_law', 'exponential'))\n",
    "print(\"Power law vs Stretched exponential:\", fit.distribution_compare('power_law', 'stretched_exponential'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Community Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate graph initial modularity\n",
    "# Defines how well a network is divided into communities range (-0.5 to 1) (higher indicates meaningful community structure)\n",
    "nx.community.modularity(G.to_undirected(), nx.community.louvain_communities(G.to_undirected(), weight='length', resolution=0.07))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Louvain community detection\n",
    "louvain = nx.community.louvain_communities(G.to_undirected(), weight='length', resolution=0.07) # change the resolution to find more or less communities\n",
    "print('Number of communities:', len(louvain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary with the community id and the node id\n",
    "dict_communities = {}\n",
    "for community_id, nodes in enumerate(louvain):\n",
    "    for node in nodes: \n",
    "        dict_communities[node] = community_id\n",
    "dict_communities\n",
    "\n",
    "# add the community id to the nodes dataframe\n",
    "df_nodes[\"louvain_community\"] = pd.Series(dict_communities) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the Graz city districts to overlay on the community \n",
    "admin_osm_tags = {'admin_level': '9', 'boundary_type': 'administrative'}\n",
    "df_districts = ox.features_from_place(CITY_NAME, admin_osm_tags)\n",
    "df_districts = df_districts.to_crs(ox.project_graph(G).graph['crs']) # project the districts to the same crs as the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = KeplerGl(height=800)\n",
    "map.add_data(data=df_districts.loc['relation'], name=\"district\") # admin district are recorded as relation polygons: get the relation index\n",
    "map.add_data(data=df_nodes[['geometry', 'louvain_community']], name=\"nodes_Graz\")\n",
    "\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this line is to clear the output of the notebook, so that when you commit it, it is clean\n",
    "!jupyter nbconvert --clear-output --inplace network_sol.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-gst.200b",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
