{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03f0eae2",
   "metadata": {},
   "source": [
    "# Exercise: Reproducing 'How close is \"close\"?' (Shingleton & Basiri, 2025)\n",
    "\n",
    "This notebook guides you through a **small-scale reproduction** of the core analytical pipeline in:\n",
    "\n",
    "- Shingleton, J., & Basiri, A. (2025). How close is \"close\"? An analysis of the spatial characteristics of perceived proximity using Large Language Models. AGILE GIScience Series, 6, 1â€“14. [10.1111/1755-2665.12276](https://doi.org/10.1111/1755-2665.12276)\n",
    "\n",
    "## ðŸŽ¯ Objectives of the Notebook\n",
    "\n",
    "1. Load **Inside Airbnb** listings for a city (London in the paper).\n",
    "2. Use a **Large Language Model (LLM)** to extract *explicitly named* places described as **near** each property.\n",
    "3. Robustly parse and clean the model output (incl. **JSON repair** and **fuzzy hallucination filtering**).\n",
    "4. Compute and interpret a **standard distance** for frequently mentioned (â€œreferenceâ€) locations.\n",
    "\n",
    "---\n",
    "\n",
    "## Working assumptions (for a classroom reproduction)\n",
    "\n",
    "- We run the LLM **locally** (via Ollama) and process a **small sample** (e.g. 200â€“500 listings).\n",
    "- We reproduce the *core logic* of the paper, not the full London-scale compute budget.\n",
    "\n",
    "> Keep notes as you go: any simplification you make is part of your reproducibility argument.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34238a9",
   "metadata": {},
   "source": [
    "## 0. Environment setup\n",
    "\n",
    "This exercise uses common data-science and geospatial libraries. If your environment is missing packages, install them below.\n",
    "\n",
    "**Libraries you will use**\n",
    "- `pandas` for tabular data\n",
    "- `geopandas` + `shapely` for geospatial data structures\n",
    "- `h3` for hexagonal indexing\n",
    "\n",
    "- `tqdm` for progress bars, because we are processing a lot of data\n",
    "\n",
    "- `ollama` for local LLM calls (or skip if you use another provider)\n",
    "- `json_repair` to handle malformed JSON from the LLM\n",
    "- `rapidfuzz` for fuzzy matching to remove hallucinated place names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566971ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed, uncomment and run:\n",
    "# %pip install -q pandas geopandas shapely h3 tqdm matplotlib ollama json_repair rapidfuzz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b52ba54",
   "metadata": {},
   "source": [
    "## 1. Imports\n",
    "\n",
    "Read this cell carefully: in a reproducible notebook, you want *all imports in one place* so dependencies are obvious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b9609e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import h3\n",
    "import ollama\n",
    "from rapidfuzz import fuzz\n",
    "from json_repair import repair_json\n",
    "\n",
    "# progress bar initialization\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7a96d2",
   "metadata": {},
   "source": [
    "## 2. Data: Inside Airbnb listings\n",
    "\n",
    "The paper uses Inside Airbnb listings for **London** and analyses property descriptions + coordinates. We will do the same analysis for Austria.\n",
    "\n",
    "For this exercise:\n",
    "- Open the [Inside Airbnb](https://insideairbnb.com/) website\n",
    "- Find a city in Austria. \n",
    "```python\n",
    "â“ `Is Graz Available?`\n",
    "```\n",
    "- Download `listings.csv.gz` from Inside Airbnb, then set `DATA_PATH` below.\n",
    "\n",
    "**Task (fill-in):** set `DATA_PATH` to your local file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f0a2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO (fill in): path to your downloaded listings.csv or listings.csv.gz\n",
    "DATA_PATH = ___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6274fa",
   "metadata": {},
   "source": [
    "## 3. Load and inspect the listings\n",
    "\n",
    "We will keep only the columns we need:\n",
    "- `id` (listing identifier)\n",
    "- `latitude`, `longitude`\n",
    "- `description` (the key text input to the LLM)\n",
    "- `neighborhood_overview` (for additional location context)\n",
    "- `neighbourhood_cleansed` (for later filtering)\n",
    "\n",
    "**ðŸš€ Tasks**\n",
    "1. How many total listings is present in the dataset?\n",
    "2. What does a typical description/neighborhood_overview look like?\n",
    "3. How many listings have missing descriptions and neighborhood_overview ? \n",
    "4. Create a kepler.gl map of all listings density based on h3 cells\n",
    "```python\n",
    "â“ `What is the coordinate reference system (CRS) of the data? Is it acceptable for our analysis?`\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a4477c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataframe \n",
    "raw_airbnb_df = pd.___(DATA_PATH)\n",
    "\n",
    "# TODO: print the number of rows of the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baf1fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only relevant columns\n",
    "use_cols = [\n",
    "    ___\n",
    "]\n",
    "\n",
    "airbnb_df = raw_airbnb_df[___].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e358df80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean na values\n",
    "# drop any row that has missing values in the columns we need\n",
    "airbnb_df = airbnb_df.dropna(subset=[___])\n",
    "\n",
    "# You can also use the parameter how='all' to drop only rows that have missing values in all columns\n",
    "# In the next step we will concatenate \"description\" and \"neighborhood_overview\"\n",
    "airbnb_df = airbnb_df.dropna(subset=[___], how='all')\n",
    "\n",
    "# TODO: print the number of of row in the cleaned sample of the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8dc0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: what look like the data? especially the description column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7596fd53",
   "metadata": {},
   "source": [
    "## 4. Spatial aggregation with H3\n",
    "\n",
    "The paper aggregates properties into an H3 grid at **resolution 7** (~5.16 kmÂ² per hexagon in their setup).  \n",
    "We will use the same default so your maps are comparable in scale.\n",
    "\n",
    "**ðŸš€ Tasks** \n",
    "1. assign for each row a h3 cell id using the `point_to_h3` function\n",
    "2. group by h3 cell id and count the number of properties in each cell\n",
    "3. create a kepler.gl map of the h3 cell density\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c67184a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create a function that will be `apply` to your dataframe \n",
    "\n",
    "H3_RES = 7\n",
    "\n",
    "def latlon_to_h3(___) -> str:\n",
    "    \"\"\"Return the H3 cell id for a (lat, lon) coordinate.\"\"\"\n",
    "    return ___\n",
    "\n",
    "airbnb_df[\"h3_cell\"] = airbnb_df.apply(point_to_h3, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1588c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: group your data by h3 cell and count the number of properties in each cell\n",
    "h3_airbnb_density = (\n",
    "    airbnb_df\n",
    "    .groupby(\"___\")\n",
    "    .___\n",
    "    .reset_index(name=\"airbnb_count\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab47fa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create a kepler.gl map of the h3 cell density"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dcbd94",
   "metadata": {},
   "source": [
    "## 5. Filter your data to only include the inner city\n",
    "\n",
    "We have definitely too many points in our dataset to do the analysis. Let's filter to only include the inner city.\n",
    "\n",
    "**ðŸš€ Task:**\n",
    "1. Filter your data to only include the inner city\n",
    "2. Create a kepler.gl map of the inner city\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7356550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: keep only data points from the inner city\n",
    "# tip: use the `neighbourhood_cleansed` column, what are the possible values? \n",
    "\n",
    "# TODO: How many data points are left?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1e6d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create a kepler.gl map of the inner city\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36386d99",
   "metadata": {},
   "source": [
    "## 6. Definition of the extraction prompt\n",
    "\n",
    "The paper uses a carefully engineered prompt (Appendix Fig. A1) to extract **explicitly named** nearby locations, excluding vague places and excluding the propertyâ€™s own location.\n",
    "\n",
    "**ðŸš€ Tasks**\n",
    "1. Read the following prompt for Vienna, is it similar of the one you are used to write?\n",
    "2. Identify **three** design choices that reduce false positives\n",
    "3. What are the differences between this prompt and the one used in the paper?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22c6718",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are an Airbnb location extraction system for Vienna. \n",
    "Your task is to extract specific Points of Interest (POIs) that are mentioned as being NEAR the property.\n",
    "\n",
    "### 1. WHAT TO EXTRACT (Positive Criteria)\n",
    "You must only extract specific, physical landmarks that can be pinpointed on a map.\n",
    "- Specific Landmarks (e.g., \"SchÃ¶nbrunn Palace\", \"St. Stephen's Cathedral\")\n",
    "- Named Squares/Streets (e.g., \"Stephansplatz\", \"Mariahilfer StraÃŸe\", \"Florianigasse\")\n",
    "- Named Markets/Parks (e.g., \"Naschmarkt\", \"Prater\", \"SchÃ¶nbornpark\")\n",
    "- Specific Transport Hubs (e.g., \"Westbahnhof\", \"U4 Pilgramgasse\")\n",
    "\n",
    "### 2. WHAT TO IGNORE (Negative Criteria)\n",
    "- IGNORE Districts and Quarters: Do NOT extract \"Neubau\", \"Favoriten\", \"1st District\", \"Freihausviertel\", \"Museumsquartier\" (unless referring to the specific complex, usually assume it's a district).\n",
    "- IGNORE Generic Amenities: Do NOT extract \"supermarkets\", \"restaurants\", \"bars\", \"shops\", \"metro station\" (if unnamed).\n",
    "- IGNORE Property Location: If the text says \"The apartment is located in [Place],\" ignore [Place]. Only extract places described as being *near*, *around*, or *walking distance* from the apartment.\n",
    "\n",
    "### 3. ADDRESS FORMATTING RULES\n",
    "- If a full address is in the text, use it.\n",
    "- If NO address is in the text, you MUST format the address as: \"[Name], Vienna\".\n",
    "- This is required formatting, not \"inventing.\"\n",
    "\n",
    "### 4. OUTPUT FORMAT\n",
    "Do not include markdown formatting or explanations.\n",
    "Keys: \"name\", \"address\", \"latitude\" (default null), \"longitude\" (default null), \"context\".\n",
    "\n",
    "### 5. FEW-SHOT EXAMPLES (Do not confuse these with your real task)\n",
    "\n",
    "Input: \"We are located in the heart of Neubau, close to the Zieglergasse station and a short walk to Mariahilfer StraÃŸe.\"\n",
    "Output:\n",
    "[\n",
    "  {\n",
    "    \"name\": \"Zieglergasse station\",\n",
    "    \"address\": \"Zieglergasse station, Vienna\",\n",
    "    \"latitude\": null,\n",
    "    \"longitude\": null,\n",
    "    \"context\": \"close to the Zieglergasse station\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Mariahilfer StraÃŸe\",\n",
    "    \"address\": \"Mariahilfer StraÃŸe, Vienna\",\n",
    "    \"latitude\": null,\n",
    "    \"longitude\": null,\n",
    "    \"context\": \"short walk to Mariahilfer StraÃŸe\"\n",
    "  }\n",
    "]\n",
    "\n",
    "Input: \"Enjoy the many shops and cafes in the 7th district. The bus takes you to the City Center.\"\n",
    "Output:\n",
    "[]\n",
    "\n",
    "Input: \"The apartment is located in the 3rd district, right next to the Belvedere Palace and just a short walk from the Rennweg station.\"\n",
    "Output:\n",
    "[\n",
    "  {\n",
    "    \"name\": \"Belvedere Palace\",\n",
    "    \"address\": \"Belvedere Palace, Vienna\",\n",
    "    \"latitude\": null,\n",
    "    \"longitude\": null,\n",
    "    \"context\": \"right next to the Belvedere Palace\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Rennweg station\",\n",
    "    \"address\": \"Rennweg station, Vienna\",\n",
    "    \"latitude\": null,\n",
    "    \"longitude\": null,\n",
    "    \"context\": \"short walk from the Rennweg station\"\n",
    "  }\n",
    "]\n",
    "Input: \"You are staying directly opposite the famous Hundertwasserhaus.\"\n",
    "Output:\n",
    "[\n",
    "  {\n",
    "    \"name\": \"Hundertwasserhaus\",\n",
    "    \"address\": \"Hundertwasserhaus, Vienna\",\n",
    "    \"latitude\": null,\n",
    "    \"longitude\": null,\n",
    "    \"context\": \"directly opposite the famous Hundertwasserhaus\"\n",
    "  }\n",
    "]\n",
    "\n",
    "### END OF EXAMPLES\n",
    "Now, analyze the following description and extract the locations based strictly on the text provided below.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d14d38",
   "metadata": {},
   "source": [
    "## 7. Calling an LLM locally (Ollama)\n",
    "\n",
    "We will call a local model via Ollama.\n",
    "- You need [Ollama](https://ollama.com/) running locally. Follow the link to download and install it.\n",
    "- You also need a model pulled (e.g., `llama3`, `qwen2`, etc.). You can find a list of available models [here](https://ollama.com/models).\n",
    "\n",
    "Running LLMs locally is extremely expensive for your RAM, Hard Drive and CPU. As a rule of thumb you need 1GB of RAM and 1GB of Hard Drive per 1B parameters. We will use a small model for this exercise: `qwen3:1.7b`.\n",
    "\n",
    "**ðŸš€ Task** \n",
    "1. set `MODEL_NAME` to a model you have locally\n",
    "2. Pull the model using `ollama.pull`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c6d724",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"qwen3:1.7b\" # You need 1.4GB of free space on your computer\n",
    "# âš ï¸ You must have Ollama running locally \n",
    "\n",
    "ollama.pull(MODEL_NAME)\n",
    "\n",
    "# Create a client to call your model \n",
    "client = ollama.Client()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebeddf5",
   "metadata": {},
   "source": [
    "### 7.1 A minimal chat wrapper\n",
    "\n",
    "- We keep temperature = 0 for deterministic outputs (useful in reproduction).\n",
    "- We allow the model to think (set `think=True`), which is useful for debugging. Not all models support this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65362294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ollama_extract_nearby(text: str, show_log: bool = True) -> str:\n",
    "    \"\"\"Return the raw model text output for one listing.\"\"\"\n",
    "\n",
    "    # define what you send to the model, the `system`` defines how the model should react, the `user` is the text you want to analyze \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": text},\n",
    "    ]\n",
    "    # you call the model here \n",
    "    resp = client.chat(\n",
    "        model=MODEL_NAME,\n",
    "        messages=messages,\n",
    "        options={\"temperature\": 0}, \n",
    "        think=True\n",
    "    )\n",
    "\n",
    "    if show_log:\n",
    "        # print the model's thinking process\n",
    "        print(\"-----\")\n",
    "        print(description)\n",
    "        print(\"\\n thinking... \\n\")\n",
    "        print(\"response\",response[\"message\"].get(\"thinking\", \"...no thinking...\"))\n",
    "        print(\"\\n\\n =>\\n\")\n",
    "        print(content)\n",
    "    \n",
    "    # return only the content of the response without the thinking part \n",
    "    return resp[\"message\"][\"content\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c5618a",
   "metadata": {},
   "source": [
    "### 7.2 Try the model on one listing\n",
    "\n",
    "**ðŸš€ Task:** \n",
    "1. Run the model on one description of your dataframe \n",
    "```python\n",
    "â“ `What is the thinking process of the model looking like?`\n",
    "â“ `Are the results correct?`\n",
    "â“ `How long does it take to run?`\n",
    "â“ `What happens if your rerun the same description? Is the output the same?`\n",
    "â“ `What happens if you change thinking to False?`\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac964e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run your function on the first row of the dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7b2f77",
   "metadata": {},
   "source": [
    "## 8) Parsing the LLM output robustly\n",
    "\n",
    "In practice, models sometimes return malformed JSON. The paper repairs JSON first, and may ask the model to fix it if needed.\n",
    "\n",
    "We will implement a two-step parser:\n",
    "1. Try `json.loads`\n",
    "2. If that fails, try `json_repair.repair_json`, then parse again\n",
    "\n",
    "**ðŸš€ Tasks** \n",
    "1. creaze the function `parse_json_array` that clean the output of the LLM and try to parse it as a JSON array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0c959d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json_array(text: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Parse a JSON array from model output, with basic repair.\"\"\"\n",
    "    text = text.strip()\n",
    "\n",
    "    # 1) direct parse\n",
    "    # TODO: wrap the json load in a try-except block\n",
    "    data = json.loads(text)\n",
    "    if isinstance(data, list):\n",
    "        return data\n",
    "\n",
    "    # 2) attempt repair\n",
    "    # TODO: use the library `json_repair` to repair the json\n",
    "    repaired = ___  # returns a JSON string\n",
    "    \n",
    "    # TODO: try to reload the repaired json\n",
    "\n",
    "    # 3) final fallback: return empty\n",
    "    return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5978c2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use the output of your LLM from earlier to parse the JSON array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac1d62e",
   "metadata": {},
   "source": [
    "## 9) Batch extraction on a small sample\n",
    "\n",
    "We will:\n",
    "- run the LLM on each airbnb listing\n",
    "- parse the JSON\n",
    "- store results in a new column `nearby_raw`\n",
    "\n",
    "**ðŸš€ Task** \n",
    "1. âš ï¸ Let select a very small sample (e.g. 3-10 rows) to test and debug your code\n",
    "2. Create a function that will be apply to each row of the dataframe to extract the locations mentioned in the description. The function should run your `ollama_extract_nearby` function and parse the JSON\n",
    "3. Apply the function to the dataframe and store the results in a new column `nearby_raw`\n",
    "4. Compute the mean number of extracted locations per listing\n",
    "5. Create a Kepler.gl map to visualize the extracted locations\n",
    "\n",
    "**ðŸ“ Note**\n",
    "- The execution might be long... so we will use `progress_apply` from `tqdm` to show a progress bar (instead of a simple `apply`)\n",
    "\n",
    "> **ðŸ“¢ TODO at home:**  \n",
    "> Run the operation on the entire dataframe and save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b2a400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a small sample of the dataframe\n",
    "small_sample = airbnb_df.sample(___)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7170b7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function that will be apply on your df\n",
    "def extract_for_row(row: str) -> List[Dict[str, Any]]:\n",
    "\n",
    "    # TODO: aggregate the columns\n",
    "\n",
    "    # you can also clean the text\n",
    "    ___ = ___.replace(\"\\n\", \" \") # remove new lines\n",
    "    ___ = ___.replace(\"<br />\", \" \") # remove html tags\n",
    "    ___ = ___.trim().lower() # remove extra spaces and lower case\n",
    "\n",
    "    if len(___)==0: # make sure the text is not empty \n",
    "        return []\n",
    "    \n",
    "    # TODO: run your LLM function\n",
    "\n",
    "    # TODO: Return the parsed value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f965d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_df[\"nearby_raw\"] = ___.progress_apply(___)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d6139f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's save our results here if you ran all your dataframe \n",
    "\n",
    "# In json\n",
    "JSON_FILEPATH = ___\n",
    "airbnb_df.to_json(JSON_FILEPATH)\n",
    "\n",
    "# in parquet\n",
    "PARQUET_FILEPATH = ___\n",
    "airbnb_df.to_parquet(PARQUET_FILEPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e87b41b",
   "metadata": {},
   "source": [
    "```python\n",
    "? `What is the difference between parquet and json? check on your disk the space of each`\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc5a1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: calculate the number of locations per row and add it as a new column\n",
    "airbnb_df[\"nearby_raw_n\"] = ___\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8cee25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create a kepler map that show the average number of nearby locations per cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef194650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding more soon..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b377a7",
   "metadata": {},
   "source": [
    "**Congratulations! ðŸŽ‰ You have successfully completed the exercise.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
