{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b5e8b0e",
   "metadata": {},
   "source": [
    "# How close is \"close\"? An analysis of the spatial characteristics of perceived proximity using Large Language Models\n",
    "\n",
    "> Shingleton, J., & Basiri, A. (2025). How close is â€œcloseâ€? An analysis of the spatial characteristics of perceived proximity using Large Language Models. AGILE GIScience Series, 6, 1â€“14. [10.1111/1755-2665.12276](https://doi.org/10.1111/1755-2665.12276)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7782de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from typing import List, Dict, Any,Tuple\n",
    "\n",
    "# global grid\n",
    "import h3 # Hexagonal grid indexing\n",
    "from keplergl import KeplerGl  \n",
    "\n",
    "# llm\n",
    "import ollama\n",
    "\n",
    "# json and text repair\n",
    "import re\n",
    "import json\n",
    "from json_repair import repair_json\n",
    "from rapidfuzz import fuzz\n",
    "\n",
    "# geocode\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "import osmnx as ox\n",
    "\n",
    "# progress bar initialization\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2d14a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_airbnb_df = pd.read_csv(\"data/listings.csv\").dropna(subset=[\"description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac7916f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. Load and inspect the listings\n",
    "\n",
    "use_cols = [ \"id\", \"latitude\", \"longitude\", \"description\", \"neighborhood_overview\", \"neighbourhood_cleansed\"]\n",
    "\n",
    "airbnb_df = raw_airbnb_df[use_cols].copy()\n",
    "airbnb_df = airbnb_df.dropna(subset=[\"latitude\", \"longitude\"])\n",
    "airbnb_df = airbnb_df.dropna(subset=[\"neighborhood_overview\", \"neighbourhood_cleansed\"], how='all')\n",
    "\n",
    "airbnb_df = airbnb_df.reset_index(drop=True)\n",
    "\n",
    "airbnb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697e6ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. Spatial aggregation with H3\n",
    "\n",
    "H3_RESOLUTION = 9\n",
    "\n",
    "# extract h3 cell id from point\n",
    "def latlon_to_h3(row: pd.Series, resolution: int = H3_RESOLUTION):\n",
    "    \"\"\"\n",
    "    Take a shapely Point (lon/lat) and return the H3 index.\n",
    "    H3 expects (lat, lon) = (y, x).\n",
    "    \"\"\"\n",
    "    return h3.latlng_to_cell(row.latitude, row.longitude, resolution)\n",
    "\n",
    "airbnb_df['h3_cell'] = airbnb_df.apply(latlon_to_h3, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8e63bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert point to h3 cell\n",
    "h3_airbnb_density = (\n",
    "    airbnb_df\n",
    "    .groupby(\"h3_cell\")\n",
    "    .size()\n",
    "    .reset_index(name=\"airbnb_count\")\n",
    ")\n",
    "\n",
    "m = KeplerGl(height=600)\n",
    "m.add_data(data=h3_airbnb_density, name=\"h3_airbnb_density\")\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9874eb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5. Filter your data to only include the inner city\n",
    "\n",
    "inner_airbnb_df = airbnb_df[airbnb_df['neighbourhood_cleansed'] == 'Innere Stadt']\n",
    "inner_airbnb_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c21d3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "h3_inner_airbnb_density = (\n",
    "    inner_airbnb_df\n",
    "    .groupby(\"h3_cell\")\n",
    "    .size()\n",
    "    .reset_index(name=\"airbnb_count\")\n",
    ")\n",
    "\n",
    "m = KeplerGl(height=600)\n",
    "m.add_data(data=h3_inner_airbnb_density, name=\"h3_inner_airbnb_density\")\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c740e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6. Definition of the extraction prompt\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are an Airbnb location extraction system for Vienna. \n",
    "Your task is to extract specific Points of Interest (POIs) that are mentioned as being NEAR the property.\n",
    "\n",
    "### 1. WHAT TO EXTRACT (Positive Criteria)\n",
    "You must only extract specific, physical landmarks that can be pinpointed on a map.\n",
    "- Specific Landmarks (e.g., \"SchÃ¶nbrunn Palace\", \"St. Stephen's Cathedral\")\n",
    "- Named Squares/Streets (e.g., \"Stephansplatz\", \"Mariahilfer StraÃŸe\", \"Florianigasse\")\n",
    "- Named Markets/Parks (e.g., \"Naschmarkt\", \"Prater\", \"SchÃ¶nbornpark\")\n",
    "- Specific Transport Hubs (e.g., \"Westbahnhof\", \"U4 Pilgramgasse\")\n",
    "\n",
    "### 2. WHAT TO IGNORE (Negative Criteria)\n",
    "- IGNORE Districts and Quarters: Do NOT extract \"Neubau\", \"Favoriten\", \"1st District\", \"Freihausviertel\", \"Museumsquartier\" (unless referring to the specific complex, usually assume it's a district).\n",
    "- IGNORE Generic Amenities: Do NOT extract \"supermarkets\", \"restaurants\", \"bars\", \"shops\", \"metro station\" (if unnamed).\n",
    "- IGNORE Property Location: If the text says \"The apartment is located in [Place],\" ignore [Place]. Only extract places described as being *near*, *around*, or *walking distance* from the apartment.\n",
    "\n",
    "### 3. ADDRESS FORMATTING RULES\n",
    "- If a full address is in the text, use it.\n",
    "- If NO address is in the text, you MUST format the address as: \"[Name], Vienna\".\n",
    "- This is required formatting, not \"inventing.\"\n",
    "\n",
    "### 4. OUTPUT FORMAT\n",
    "Do not include markdown formatting or explanations.\n",
    "Keys: \"name\", \"address\", \"latitude\" (default null), \"longitude\" (default null), \"context\".\n",
    "\n",
    "### 5. FEW-SHOT EXAMPLES (Do not confuse these with your real task)\n",
    "\n",
    "Input: \"We are located in the heart of Neubau, close to the Zieglergasse station and a short walk to Mariahilfer StraÃŸe.\"\n",
    "Output:\n",
    "[\n",
    "  {\n",
    "    \"name\": \"Zieglergasse station\",\n",
    "    \"address\": \"Zieglergasse station, Vienna\",\n",
    "    \"latitude\": null,\n",
    "    \"longitude\": null,\n",
    "    \"context\": \"close to the Zieglergasse station\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Mariahilfer StraÃŸe\",\n",
    "    \"address\": \"Mariahilfer StraÃŸe, Vienna\",\n",
    "    \"latitude\": null,\n",
    "    \"longitude\": null,\n",
    "    \"context\": \"short walk to Mariahilfer StraÃŸe\"\n",
    "  }\n",
    "]\n",
    "\n",
    "Input: \"Enjoy the many shops and cafes in the 7th district. The bus takes you to the City Center.\"\n",
    "Output:\n",
    "[]\n",
    "\n",
    "Input: \"The apartment is located in the 3rd district, right next to the Belvedere Palace and just a short walk from the Rennweg station.\"\n",
    "Output:\n",
    "[\n",
    "  {\n",
    "    \"name\": \"Belvedere Palace\",\n",
    "    \"address\": \"Belvedere Palace, Vienna\",\n",
    "    \"latitude\": null,\n",
    "    \"longitude\": null,\n",
    "    \"context\": \"right next to the Belvedere Palace\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Rennweg station\",\n",
    "    \"address\": \"Rennweg station, Vienna\",\n",
    "    \"latitude\": null,\n",
    "    \"longitude\": null,\n",
    "    \"context\": \"short walk from the Rennweg station\"\n",
    "  }\n",
    "]\n",
    "Input: \"You are staying directly opposite the famous Hundertwasserhaus.\"\n",
    "Output:\n",
    "[\n",
    "  {\n",
    "    \"name\": \"Hundertwasserhaus\",\n",
    "    \"address\": \"Hundertwasserhaus, Vienna\",\n",
    "    \"latitude\": null,\n",
    "    \"longitude\": null,\n",
    "    \"context\": \"directly opposite the famous Hundertwasserhaus\"\n",
    "  }\n",
    "]\n",
    "\n",
    "### END OF EXAMPLES\n",
    "Now, analyze the following description and extract the locations based strictly on the text provided below.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4388d6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7. Calling an LLM locally (Ollama)\n",
    "\n",
    "MODEL_NAME = \"qwen3:1.7b\"\n",
    "\n",
    "ollama.pull(MODEL_NAME)\n",
    "\n",
    "# Create a client to call your model \n",
    "client = ollama.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4301f853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ollama_extract_nearby(text: str, show_log: bool = True) -> Tuple[str, str]:\n",
    "    \"\"\"Return the raw model text output for one listing.\"\"\"\n",
    "\n",
    "    # define what you send to the model, the `system`` defines how the model should react, the `user` is the text you want to analyze \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": text},\n",
    "    ]\n",
    "    # you call the model here \n",
    "    resp = client.chat(\n",
    "        model=MODEL_NAME,\n",
    "        messages=messages,\n",
    "        options={\"temperature\": 0}, \n",
    "        think=True\n",
    "    )\n",
    "\n",
    "    model_text = resp[\"message\"][\"content\"]\n",
    "    thinking = resp[\"message\"].get(\"thinking\", \"...no thinking...\")\n",
    "\n",
    "    if show_log:\n",
    "        # print the model's thinking process\n",
    "        print(\"-----\")\n",
    "        print(text)\n",
    "        print(\"\\n thinking... \\n\")\n",
    "        print(\"response\",thinking)\n",
    "        print(\"\\n\\n =>\\n\")\n",
    "        print(model_text)\n",
    "    \n",
    "    # return only the content of the response without the thinking part \n",
    "    return model_text, thinking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3870bf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 8. Parsing the LLM output robustly\n",
    "\n",
    "def parse_json_array(content: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Try to parse the model output as a JSON array of objects.\n",
    "    Be tolerant of minor formatting issues.\n",
    "    \"\"\"\n",
    "    # First, optimistic: treat the whole content as JSON\n",
    "    try:\n",
    "        data = json.loads(content)\n",
    "        if isinstance(data, list):\n",
    "            return data\n",
    "        # If the model returned an object, you might decide how to handle it,\n",
    "        # but for this task we expect a list.\n",
    "    except json.JSONDecodeError:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    # Second, optimistic: treat the whole content as JSON\n",
    "    try:\n",
    "        \n",
    "        data = repair_json(content)\n",
    "        data = json.loads(data)\n",
    "        if isinstance(data, list):\n",
    "            return data\n",
    "        # If the model returned an object, you might decide how to handle it,\n",
    "        # but for this task we expect a list.\n",
    "    except json.JSONDecodeError:\n",
    "        pass\n",
    "\n",
    "    # Second, try to extract the first JSON array from the text\n",
    "    match = re.search(r\"\\[\\s*\\{.*?\\}\\s*\\]\", content, flags=re.DOTALL)\n",
    "    if match:\n",
    "        try:\n",
    "            data = json.loads(match.group(0))\n",
    "            if isinstance(data, list):\n",
    "                return data\n",
    "        except json.JSONDecodeError:\n",
    "            pass\n",
    "    \n",
    "\n",
    "    # Fallback: nothing parseable\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69db7be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 9. Batch extraction on a small sample\n",
    "\n",
    "def extract_for_row(row) -> pd.Series:\n",
    "\n",
    "    out = pd.Series({\n",
    "        \"locations\": [],\n",
    "        \"thinking\": None\n",
    "    })\n",
    "\n",
    "    desc = row.get(\"description\", \"\")\n",
    "    neigh = row.get(\"neighborhood_overview\", \"\")\n",
    "\n",
    "    content = f\"{desc} {neigh}\".strip()\n",
    "    # you can also clean the text\n",
    "    content = content.replace(\"\\n\", \" \") # remove new lines\n",
    "    content = content.replace(\"<br />\", \" \") # remove html tags\n",
    "\n",
    "    if not content:\n",
    "        return out\n",
    "\n",
    "    try:    \n",
    "        locations, thinking = ollama_extract_nearby(content)\n",
    "        out[\"locations\"] = parse_json_array(locations)\n",
    "        out[\"thinking\"] = thinking\n",
    "        return out \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting locations for row: {e}\")\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acfa814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a small sample of the dataframe\n",
    "small_sample = airbnb_df.sample(10)\n",
    "\n",
    "small_sample[[\"locations\", \"thinking\"]] = small_sample.progress_apply(extract_for_row, axis=1)\n",
    "\n",
    "# change to inner_airbnb_df to run all the listings in the inner city\n",
    "# inner_airbnb_df[[\"locations\", \"thinking\"]] = inner_airbnb_df.progress_apply(extract_for_row, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858177cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 9. Reduce hallucinations with fuzzy presence checks\n",
    "\n",
    "# open parquet from data folder if needed\n",
    "inner_airbnb_df = pd.read_parquet(\"data/airbnb_nearby.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc533f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESH = 70\n",
    "\n",
    "def filter_dicts_by_presence(row):\n",
    "    # 1. Prepare the text to search in\n",
    "\n",
    "    full_text = f\"{row['description']} {row['neighborhood_overview']}\".lower()\n",
    "    \n",
    "    kept_dicts = []\n",
    "    \n",
    "    # 2. Iterate through the existing list\n",
    "    metadata_list = row['locations']\n",
    "    print(metadata_list)\n",
    "\n",
    "    for item in metadata_list:\n",
    "        name = item.get('name', '')\n",
    "        print(name)\n",
    "        if not name:\n",
    "            continue\n",
    "            \n",
    "        # 3. Keep the dict only if the name is found in the text\n",
    "        # partial_ratio > 85 ensures it's a strong match (handles minor typos)\n",
    "        if fuzz.partial_ratio(name.lower(), full_text) >= THRESH:\n",
    "            print(\"Found\")\n",
    "            kept_dicts.append(item)\n",
    "    print(\"-\"*10)\n",
    "    return kept_dicts\n",
    "\n",
    "inner_airbnb_df['cleaned_metadata_list'] = inner_airbnb_df.progress_apply(filter_dicts_by_presence, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6bfe1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 10. Adding missing coordinates to the cleaned locations\n",
    "\n",
    "# 1. Initialize Nominatim\n",
    "# IMPORTANT: You MUST provide a custom user_agent to identify your app\n",
    "geolocator = Nominatim(user_agent=\"my_academic_project_graz_university\")\n",
    "\n",
    "# 2. Create a rate-limited version of the geocode function\n",
    "# This automatically waits 1 second between calls to avoid banning\n",
    "geocode_safe = RateLimiter(geolocator.geocode, min_delay_seconds=1.1)\n",
    "\n",
    "# 3. Define a function to process your list of dicts\n",
    "def geocode_locations(metadata_list):\n",
    "    if not isinstance(metadata_list, list):\n",
    "        return metadata_list\n",
    "    \n",
    "    for location in metadata_list:\n",
    "        address = location.get(\"address\")\n",
    "        print(address)\n",
    "        if address:\n",
    "            try:\n",
    "                # Call the safe geocoder\n",
    "                loc = geocode_safe(address)\n",
    "                print(loc)\n",
    "                print(loc.latitude)\n",
    "                print(loc.longitude)\n",
    "                print(\"-\" * 10)\n",
    "                if loc:\n",
    "                    location[\"latitude\"] = loc.latitude\n",
    "                    location[\"longitude\"] = loc.longitude\n",
    "                else:\n",
    "                    location[\"latitude\"] = None\n",
    "                    location[\"longitude\"] = None\n",
    "                    # print(f\"No location found for: {address}\") # Optional logging\n",
    "            except Exception as e:\n",
    "                print(f\"Error geocoding {address}: {e}\")\n",
    "                location[\"latitude\"] = None\n",
    "                location[\"longitude\"] = None\n",
    "    return metadata_list\n",
    "\n",
    "# 4. Apply with progress bar & run the process\n",
    "tqdm.pandas()\n",
    "inner_airbnb_df['cleaned_metadata_list'] = inner_airbnb_df['cleaned_metadata_list'].progress_apply(geocode_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8966af56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open parquet from data folder if needed\n",
    "inner_airbnb_df = pd.read_parquet(\"data/airbnb_nearby_with_coordinates.parquet\")\n",
    "list(inner_airbnb_df.locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c906741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get vienna geometry \n",
    "PLACE_NAME = \"Vienna, Austria\"\n",
    "\n",
    "# Get the boundary polygon of Vienna and project it to EPSG:31256\n",
    "poly_border_vienna = ox.geocode_to_gdf(PLACE_NAME)\n",
    "poly_border_vienna.plot()\n",
    "\n",
    "vienna_polygon = poly_border_vienna.geometry.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363b40d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the coordinates if not in vienna or null\n",
    "\n",
    "def clean_coordinates(row, geometry):\n",
    "    # get bbox of vienna from the geometry\n",
    "    min_lon, min_lat, max_lon, max_lat = geometry.bounds\n",
    "\n",
    "    kept_dicts = [] # init a dict for returning the filtered values \n",
    "    for item in row['locations']:\n",
    "        lon, lat = item.get('longitude'), item.get('latitude')\n",
    "\n",
    "        # missing coordinates\n",
    "        if lon is None or lat is None:\n",
    "            continue\n",
    "\n",
    "        # coordinates outside vienna\n",
    "        if not (min_lon <= lon <= max_lon and min_lat <= lat <= max_lat):\n",
    "            continue\n",
    "        \n",
    "        kept_dicts.append(item)\n",
    "            \n",
    "    return kept_dicts\n",
    "\n",
    "# Apply to your column\n",
    "inner_airbnb_df['cleaned_locations'] = inner_airbnb_df.apply(lambda row: clean_coordinates(row, vienna_polygon), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a198431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count addresses\n",
    "inner_airbnb_df['location_count'] = inner_airbnb_df['locations'].apply(lambda x: len(x))\n",
    "inner_airbnb_df['cleaned_location_count'] = inner_airbnb_df['cleaned_locations'].apply(lambda x: len(x))\n",
    "inner_airbnb_df[\"dropped_addresses\"] = inner_airbnb_df['location_count'] - inner_airbnb_df['cleaned_location_count']\n",
    "\n",
    "h3_adr_dropped = (\n",
    "    inner_airbnb_df\n",
    "    .groupby(\"h3_cell\")['dropped_addresses']\n",
    "    .sum()\n",
    "    .reset_index(name=\"dropped_adr\")\n",
    ")\n",
    "\n",
    "m = KeplerGl(height=600)\n",
    "m.add_data(data=h3_adr_dropped, name=\"h3_adr_dropped\")\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4906fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 11. Reference locations and â€œarea of influenceâ€ (standard distance)\n",
    "\n",
    "airbnb_df_exploded = inner_airbnb_df.explode(\"cleaned_locations\", ignore_index=True).dropna(subset=[\"cleaned_locations\"]).reset_index(drop=True)\n",
    "airbnb_df_exploded[\"loc_name\"] = airbnb_df_exploded.cleaned_locations.str[\"name\"]\n",
    "airbnb_df_exploded[\"loc_lat\"] = airbnb_df_exploded.cleaned_locations.str[\"latitude\"]\n",
    "airbnb_df_exploded[\"loc_lon\"] = airbnb_df_exploded.cleaned_locations.str[\"longitude\"]\n",
    "airbnb_df_exploded.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb62f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change display options to show all rows\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "airbnb_df_exploded.loc_name.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40064b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset count option\n",
    "pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0683ff28",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = airbnb_df_exploded.loc_name.value_counts().head(25)\n",
    "fig = px.histogram(x=value_counts.index, \n",
    "    y=value_counts.values,\n",
    "    labels={'x': 'Location Name', 'y': 'Count'}, height=400)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fc6bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance haversine\n",
    "\n",
    "EARTH_RADIUS_KM = 6371.0088\n",
    "\n",
    "def haversine_km(lat1: float, lon1: float, lat2: float, lon2: float) -> float:\n",
    "    \"\"\"Great-circle distance (km) between two WGS84 points.\"\"\"\n",
    "    # TODO (fill in): implement haversine\n",
    "    phi1 = math.radians(lat1)\n",
    "    phi2 = math.radians(lat2)\n",
    "    dphi = math.radians(lat2 - lat1)\n",
    "    dlambda = math.radians(lon2 - lon1)\n",
    "\n",
    "    a = math.sin(dphi/2)**2 + math.cos(phi1)*math.cos(phi2)*math.sin(dlambda/2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n",
    "    return EARTH_RADIUS_KM * c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5daeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get distance\n",
    "airbnb_df_exploded = airbnb_df_exploded.dropna(subset=['longitude', 'latitude', 'loc_lon', 'loc_lat'])\n",
    "airbnb_df_exploded['distance'] = airbnb_df_exploded.apply(lambda row: haversine_km(row['longitude'],row['latitude'], row['loc_lon'], row['loc_lat']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65deceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "h3_airbnb_density = (\n",
    "    airbnb_df_exploded\n",
    "    .groupby(\"h3_cell\")['distance']\n",
    "    .mean()\n",
    "    .reset_index(name=\"avg_distance\")\n",
    ")\n",
    "\n",
    "m = KeplerGl(height=600)\n",
    "m.add_data(data=h3_airbnb_density, name=\"avg_distance\")\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9827dd",
   "metadata": {},
   "source": [
    "**Congratulations! ðŸŽ‰ You have successfully completed the exercise.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e3c5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this line is to clear the output of the notebook, so that when you commit it, it is clean\n",
    "!jupyter nbconvert --clear-output --inplace crime_ex.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
